---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    lsst.io/rule: "true"
  name: metallb
spec:
  groups:
    - name: metallb.rules
      rules:
        - alert: MetalLBStaleConfig
          annotations:
            message: '{{ $labels.job }} - MetalLB {{ $labels.container }} on {{ $labels.pod
              }} has a stale config for > 1 minute'
          expr: metallb_k8s_client_config_stale_bool{job="metallb"} == 1
          for: 1m
          labels:
            severity: warning

        - alert: MetalLBConfigNotLoaded
          annotations:
            message: '{{ $labels.job }} - MetalLB {{ $labels.container }} on {{ $labels.pod
              }} has not loaded for > 1 minute'
          expr: metallb_k8s_client_config_loaded_bool{job="metallb"} == 0
          for: 1m
          labels:
            severity: warning

        - alert: MetalLBAddressPoolExhausted
          annotations:
            message: '{{ $labels.job }} - MetalLB {{ $labels.container }} on {{ $labels.pod
              }} has exhausted address pool {{ $labels.pool }} for > 1 minute'
          expr: metallb_allocator_addresses_in_use_total{pool!~".*ingress.*"} >= on(pool) metallb_allocator_addresses_total
          for: 1m
          labels:
            severity: alert

        - alert: MetalLBAddressPoolUsage80Percent
          annotations:
            message: '{{ $labels.job }} - MetalLB {{ $labels.container }} on {{ $labels.pod
              }} has address pool {{ $labels.pool }} past 80% usage for > 1 minute'
          expr: ( metallb_allocator_addresses_in_use_total{pool!~".*ingress.*"} / on(pool) metallb_allocator_addresses_total
            ) * 100 > 80
          labels:
            severity: warning

        - alert: MetalLBAddressPoolUsage90Percent
          annotations:
            message: '{{ $labels.job }} - MetalLB {{ $labels.container }} on {{ $labels.pod
              }} has address pool {{ $labels.pool }} past 90% usage for > 1 minute'
          expr: ( metallb_allocator_addresses_in_use_total{pool!~".*ingress.*"} / on(pool) metallb_allocator_addresses_total
            ) * 100 > 90
          labels:
            severity: alert

        - alert: MetalLBBGPSessionDown
          annotations:
            message: '{{ $labels.job }} - MetalLB {{ $labels.container }} on {{ $labels.pod
              }} has BGP session {{ $labels.peer }} down for > 1 minute'
          expr: metallb_bgp_session_up{job="metallb"} == 0
          for: 1m
          labels:
            severity: alert
